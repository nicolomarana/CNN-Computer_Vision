{"nbformat":4,"nbformat_minor":0,"metadata":{"coursera":{"course_slug":"convolutional-neural-networks","graded_item_id":"owWbQ","launcher_item_id":"lEthw"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"Neural Style Transfer (Art).ipynb","provenance":[],"collapsed_sections":["5JxbOR-SR1qE","7q7ptjW5R1qd","f0i-m8CVR1qi","kYpABs8_R1qv"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"x8-90nNwR1p9","colab_type":"text"},"source":["# Deep Learning & Art: Neural Style Transfer\n"]},{"cell_type":"code","metadata":{"id":"rCiXwDLMR1p-","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import scipy.io\n","import scipy.misc\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import imshow\n","from PIL import Image\n","from nst_utils import *\n","import numpy as np\n","import tensorflow as tf\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5JxbOR-SR1qE","colab_type":"text"},"source":["## 1 - Transfer Learning\n"]},{"cell_type":"code","metadata":{"id":"NOOozp31R1qE","colab_type":"code","colab":{}},"source":["model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\n","print(model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w0EI1wlJR1qK","colab_type":"text"},"source":["## 2 - Neural Style Transfer \n","\n","\n","### 2.1 - Computing the content cost\n"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"ExA_-rAjR1qL","colab_type":"code","colab":{}},"source":["content_image = scipy.misc.imread(\"images/louvre.jpg\")\n","imshow(content_image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySAEsR1eR1qQ","colab_type":"code","colab":{}},"source":["def compute_content_cost(a_C, a_G):\n","    \"\"\"\n","    Computes the content cost\n","    \n","    Arguments:\n","    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n","    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n","    \n","    Returns: \n","    J_content -- scalar that you compute using equation 1 above.\n","    \"\"\"\n","    \n","    ### START CODE HERE ###\n","    # Retrieve dimensions from a_G (≈1 line)\n","    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n","    \n","    # Reshape a_C and a_G (≈2 lines)\n","    a_C_unrolled = tf.transpose(tf.reshape(a_C, [-1]))\n","    a_G_unrolled = tf.transpose(tf.reshape(a_G, [-1]))\n","    \n","    # compute the cost with tensorflow (≈1 line)\n","    J_content =  tf.reduce_sum((a_C_unrolled - a_G_unrolled)**2) / (4*n_H*n_W*n_C)\n","    ### END CODE HERE ###\n","    \n","    return J_content"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"69JDKsmNR1qT","colab_type":"code","colab":{}},"source":["tf.reset_default_graph()\n","\n","with tf.Session() as test:\n","    tf.set_random_seed(1)\n","    a_C = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n","    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n","    J_content = compute_content_cost(a_C, a_G)\n","    print(\"J_content = \" + str(J_content.eval()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MaLBnvWgR1qW","colab_type":"text"},"source":["### 2.2 - Computing the style cost"]},{"cell_type":"code","metadata":{"id":"JQn3tKO7R1qa","colab_type":"code","colab":{}},"source":["style_image = scipy.misc.imread(\"images/monet_800600.jpg\")\n","imshow(style_image)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7q7ptjW5R1qd","colab_type":"text"},"source":["### 2.2.1 - Style matrix"]},{"cell_type":"code","metadata":{"id":"NYRRpRvPR1qd","colab_type":"code","colab":{}},"source":["def gram_matrix(A):\n","    \"\"\"\n","    Argument:\n","    A -- matrix of shape (n_C, n_H*n_W)\n","    \n","    Returns:\n","    GA -- Gram matrix of A, of shape (n_C, n_C)\n","    \"\"\"\n","    \n","    ### START CODE HERE ### (≈1 line)\n","    GA = tf.matmul(A, A, False, True)\n","    ### END CODE HERE ###\n","    \n","    return GA"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwuRECKdR1qg","colab_type":"code","colab":{}},"source":["tf.reset_default_graph()\n","\n","with tf.Session() as test:\n","    tf.set_random_seed(1)\n","    A = tf.random_normal([3, 2*1], mean=1, stddev=4)\n","    GA = gram_matrix(A)\n","    \n","    print(\"GA = \" + str(GA.eval()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f0i-m8CVR1qi","colab_type":"text"},"source":["### 2.2.2 - Style cost"]},{"cell_type":"code","metadata":{"id":"cO_8E2bkR1ql","colab_type":"code","colab":{}},"source":["def compute_layer_style_cost(a_S, a_G):\n","    \"\"\"\n","    Arguments:\n","    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n","    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n","    \n","    Returns: \n","    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n","    \"\"\"\n","    \n","    ### START CODE HERE ###\n","    # Retrieve dimensions from a_G (≈1 line)\n","    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n","    \n","    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)\n","    a_S = tf.reshape(a_S, [n_H*n_W, n_C])\n","    a_G = tf.reshape(a_G, [n_H*n_W, n_C])\n","\n","    # Computing gram_matrices for both images S and G (≈2 lines)\n","    GS = gram_matrix(tf.transpose(a_S))\n","    GG = gram_matrix(tf.transpose(a_G))\n","\n","    # Computing the loss (≈1 line)\n","    J_style_layer = tf.reduce_sum((GS - GG)**2) / (4 * n_C**2 * (n_W * n_H)**2)\n","    \n","    ### END CODE HERE ###\n","    \n","    return J_style_layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"952F_ZUqR1qr","colab_type":"code","colab":{}},"source":["tf.reset_default_graph()\n","\n","with tf.Session() as test:\n","    tf.set_random_seed(1)\n","    a_S = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n","    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n","    J_style_layer = compute_layer_style_cost(a_S, a_G)\n","    \n","    print(\"J_style_layer = \" + str(J_style_layer.eval()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kYpABs8_R1qv","colab_type":"text"},"source":["### 2.2.3 Style Weights\n"]},{"cell_type":"code","metadata":{"id":"Jl0T8BZxR1qv","colab_type":"code","colab":{}},"source":["STYLE_LAYERS = [\n","    ('conv1_1', 0.2),\n","    ('conv2_1', 0.2),\n","    ('conv3_1', 0.2),\n","    ('conv4_1', 0.2),\n","    ('conv5_1', 0.2)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aNOmHnKOR1qz","colab_type":"code","colab":{}},"source":["def compute_style_cost(model, STYLE_LAYERS):\n","    \"\"\"\n","    Computes the overall style cost from several chosen layers\n","    \n","    Arguments:\n","    model -- our tensorflow model\n","    STYLE_LAYERS -- A python list containing:\n","                        - the names of the layers we would like to extract style from\n","                        - a coefficient for each of them\n","    \n","    Returns: \n","    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n","    \"\"\"\n","    \n","    # initialize the overall style cost\n","    J_style = 0\n","\n","    for layer_name, coeff in STYLE_LAYERS:\n","\n","        # Select the output tensor of the currently selected layer\n","        out = model[layer_name]\n","\n","        # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out\n","        a_S = sess.run(out)\n","\n","        # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] \n","        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n","        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n","        a_G = out\n","        \n","        # Compute style_cost for the current layer\n","        J_style_layer = compute_layer_style_cost(a_S, a_G)\n","\n","        # Add coeff * J_style_layer of this layer to overall style cost\n","        J_style += coeff * J_style_layer\n","\n","    return J_style"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"62Q_ENXcR1q1","colab_type":"text"},"source":["### 2.3 - Defining the total cost to optimize"]},{"cell_type":"code","metadata":{"id":"F3Lxx68fR1q2","colab_type":"code","colab":{}},"source":["def total_cost(J_content, J_style, alpha = 10, beta = 40):\n","    \"\"\"\n","    Computes the total cost function\n","    \n","    Arguments:\n","    J_content -- content cost coded above\n","    J_style -- style cost coded above\n","    alpha -- hyperparameter weighting the importance of the content cost\n","    beta -- hyperparameter weighting the importance of the style cost\n","    \n","    Returns:\n","    J -- total cost as defined by the formula above.\n","    \"\"\"\n","    \n","    ### START CODE HERE ### (≈1 line)\n","    J = alpha * J_content + beta * J_style\n","    ### END CODE HERE ###\n","    \n","    return J"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L4V3xg2uR1q5","colab_type":"code","colab":{}},"source":["tf.reset_default_graph()\n","\n","with tf.Session() as test:\n","    np.random.seed(3)\n","    J_content = np.random.randn()    \n","    J_style = np.random.randn()\n","    J = total_cost(J_content, J_style)\n","    print(\"J = \" + str(J))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QtJQTV9kR1q9","colab_type":"text"},"source":["## 3 - Solving the optimization problem"]},{"cell_type":"code","metadata":{"id":"3bAFiki_R1rA","colab_type":"code","colab":{}},"source":["content_image = scipy.misc.imread(\"images/louvre_small.jpg\")\n","content_image = reshape_and_normalize_image(content_image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_mKY-3gR1rE","colab_type":"code","colab":{}},"source":["style_image = scipy.misc.imread(\"images/monet.jpg\")\n","style_image = reshape_and_normalize_image(style_image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2YrH8wIrR1rH","colab_type":"code","colab":{}},"source":["generated_image = generate_noise_image(content_image)\n","imshow(generated_image[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4U1HtDVmR1rN","colab_type":"code","colab":{}},"source":["model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_eSCVdGR1rS","colab_type":"code","colab":{}},"source":["# Assign the content image to be the input of the VGG model.  \n","sess.run(model['input'].assign(content_image))\n","\n","# Select the output tensor of layer conv4_2\n","out = model['conv4_2']\n","\n","# Set a_C to be the hidden layer activation from the layer we have selected\n","a_C = sess.run(out)\n","\n","# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] \n","# and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n","# when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n","a_G = out\n","\n","# Compute the content cost\n","J_content = compute_content_cost(a_C, a_G)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P4tl3NvMR1rU","colab_type":"code","colab":{}},"source":["# Assign the input of the model to be the \"style\" image \n","sess.run(model['input'].assign(style_image))\n","\n","# Compute the style cost\n","J_style = compute_style_cost(model, STYLE_LAYERS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"codSnZVuR1rW","colab_type":"code","colab":{}},"source":["### START CODE HERE ### (1 line)\n","J = total_cost(J_content, J_style, alpha=10, beta=40)\n","### END CODE HERE ###"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NrJLrLLjR1rZ","colab_type":"code","colab":{}},"source":["# define optimizer (1 line)\n","optimizer = tf.train.AdamOptimizer(2.0)\n","\n","# define train_step (1 line)\n","train_step = optimizer.minimize(J)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aF6JdrKaR1rd","colab_type":"code","colab":{}},"source":["def model_nn(sess, input_image, num_iterations = 200):\n","    \n","    # Initialize global variables (you need to run the session on the initializer)\n","    ### START CODE HERE ### (1 line)\n","    sess.run(tf.global_variables_initializer())\n","    ### END CODE HERE ###\n","    \n","    # Run the noisy input image (initial generated image) through the model. Use assign().\n","    ### START CODE HERE ### (1 line)\n","    sess.run(model['input'].assign(input_image))\n","    ### END CODE HERE ###\n","    \n","    for i in range(num_iterations):\n","    \n","        # Run the session on the train_step to minimize the total cost\n","        ### START CODE HERE ### (1 line)\n","        _ = sess.run(train_step)\n","        ### END CODE HERE ###\n","        \n","        # Compute the generated image by running the session on the current model['input']\n","        ### START CODE HERE ### (1 line)\n","        generated_image = sess.run(model['input'])\n","        ### END CODE HERE ###\n","\n","        # Print every 20 iteration.\n","        if i%20 == 0:\n","            Jt, Jc, Js = sess.run([J, J_content, J_style])\n","            print(\"Iteration \" + str(i) + \" :\")\n","            print(\"total cost = \" + str(Jt))\n","            print(\"content cost = \" + str(Jc))\n","            print(\"style cost = \" + str(Js))\n","            \n","            # save current generated image in the \"/output\" directory\n","            save_image(\"output/\" + str(i) + \".png\", generated_image)\n","    \n","    # save last generated image\n","    save_image('output/generated_image.jpg', generated_image)\n","    \n","    return generated_image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"dSFrVfoxR1rf","colab_type":"code","colab":{}},"source":["model_nn(sess, generated_image)"],"execution_count":0,"outputs":[]}]}